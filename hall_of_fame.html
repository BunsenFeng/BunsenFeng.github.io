<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-7MZLF35N8T"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-7MZLF35N8T');
    </script>
    <title>Shangbin Feng</title>
    <link rel="icon" type="image/x-icon" href="file/new_new_photo.jpg">
    <style>
    .grid-container {
      display: grid;
      grid-template-columns: 20% 20% 60% 20%;
      grid-template-rows: auto auto;
      padding: 10px;
      justify-content: center;
      column-gap: 10px;
    }
 
    .grid-item {
      background-color: rgba(255, 255, 255, 0.8);
      font-size: 18px;
      text-align: left;
      vertical-align: middle;
    }
    p {
      margin:20px;
      padding:0px;
      font-family: "Helvetica Neue", "Helvetica", sans-serif;
    }
    a.button {
    -webkit-appearance: button;
    -moz-appearance: button;
    appearance: button;

    text-decoration: none;
    color: white;
    background-color: #6AA84F;
    border: 0.5px solid black;
    border-radius: 5px;
    padding: 5px;
    font-size: 90%;
    }
    img {
    padding-top: 12px;
    display: block;
    margin-left: auto;
    margin-right: auto;
    max-width: 100%;
    max-height: 100%;
    }
    ul {
      font-family: "Helvetica Neue", "Helvetica", sans-serif;
    }
    </style>
</head>

<body>

<div class="grid-container">
    <div class="grid-item"></div>
    <div class="grid-item">
      <img src="file/new_new_photo.jpg" alt="Shangbin photo">
    </div>
    <div class="grid-item">
      <p style="text-align:left;font-size:220%;"><b>Shangbin Feng</b></p>
      <p style="text-align:left;">
        PhD student at University of Washington, working with <a href="https://homes.cs.washington.edu/~yuliats/">Yulia Tsvetkov</a>. Multi-LLM collaboration, social NLP, networks and structures.
      </p>
      <p> Links: &nbsp
        <a href="file/CV.pdf" class="button">CV</a> &nbsp
        <a href="mailto:shangbin@cs.washington.edu" class="button">Email</a> &nbsp
        <a href="https://twitter.com/shangbinfeng" class="button">Twitter</a> &nbsp
        <a href="https://github.com/BunsenFeng" class="button">Github</a> &nbsp
        <a href="https://scholar.google.com/citations?user=Y3rLP9UAAAAJ&hl=en&oi=ao" class="button">Google Scholar</a> &nbsp
        <a href="https://www.semanticscholar.org/author/Shangbin-Feng/2114887261" class="button">Semantic Scholar</a>
      </p>
    </div>
    <div class="grid-item"></div>
</div>

<hr style="width:80%">

<div class="grid-container">
  <div class="grid-item"></div>
  <div class="grid-item">
    <p style="text-align:left;font-size:150%;">Publications</p>
  </div>
  <div class="grid-item">
      <p> Filter: &nbsp
        <a href="hall_of_fame.html" class="button"><b>Hall of Fame üèÜ</b></a> &nbsp
        <a href="index.html" class="button">Lead/co-Lead ‚úçÔ∏è</a> &nbsp
        <a href="all_papers.html" class="button">All Papers üìñ</a> &nbsp
      </p>
  </div>
  <div class="grid-item"></div>
</div>

<div class="grid-container">
  <div class="grid-item"></div>
  <div class="grid-item">
    <img src="file/AbstainQA_teaser.png" alt="AbstainQA Teaser">
  </div>
  <div class="grid-item">
    <p>
      <b>Don't Hallucinate, Abstain: Identifying LLM Knowledge Gaps via Multi-LLM Collaboration</b>
    </p>
    <p>
        <b>Shangbin Feng</b>, <a href="https://swj0419.github.io/">Weijia Shi</a>, <a href="https://yikee.github.io/">Yike Wang</a>, <a href="https://wenwen-d.github.io/">Wenxuan Ding</a>, <a href="https://vidhishanair.github.io/">Vidhisha Balachandran</a>, <a href="https://homes.cs.washington.edu/~yuliats/">Yulia Tsvetkov</a>
    </p>
    <p>
      ACL 2024 &nbsp üèÜ Area Chair Award, QA Track &nbsp üèÜ Outstanding Paper Award &nbsp
      <a href="https://arxiv.org/abs/2402.00367" class="button">paper</a> &nbsp
      <a href="https://github.com/BunsenFeng/AbstainQA" class="button">code</a> &nbsp
    </p>
    <p>
       We benchmark LLM abstention with calibration-, training-, prompting-, and consistency-based approaches. Informed by their weaknesses, we propose collaboration-based approaches, where multiple LLMs work in cooperation or competition to identify the knowledge gaps in each other and produce abstain decisions.
    </p>
  </div>
  <div class="grid-item"></div>
</div>

<div class="grid-container">
  <div class="grid-item"></div>
  <div class="grid-item">
    <img src="file/CooK_teaser.jpg" alt="CooK Teaser">
  </div>
  <div class="grid-item">
    <p>
      <b>Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models</b>
    </p>
    <p>
        <b>Shangbin Feng</b>, <a href="https://swj0419.github.io/">Weijia Shi</a>, <a href="https://leopoldwhite.github.io/">Yuyang Bai</a>, <a href="https://vidhishanair.github.io/">Vidhisha Balachandran</a>, <a href="https://people.csail.mit.edu/cloudygoose/">Tianxing He</a>, <a href="https://homes.cs.washington.edu/~yuliats/">Yulia Tsvetkov</a> 
    </p>
    <p>
      ICLR 2024, oral &nbsp
      <a href="https://arxiv.org/abs/2305.09955" class="button">paper</a> &nbsp
      <a href="https://github.com/BunsenFeng/Knowledge_Card/tree/main" class="button">code</a> &nbsp
    </p>
    <p>
       We propose Knowledge Card, a community-driven initiative to empower black-box LLMs with modular and collaborative knowledge. By incorporating the outputs of independently trained, small, and specialized LMs, we make LLMs better knowledge models by empowering them with temporal knowledge update, multi-domain knowledge synthesis, and continued improvement through collective efforts. 
    </p>
  </div>
  <div class="grid-item"></div>
</div>

<div class="grid-container">
  <div class="grid-item"></div>
  <div class="grid-item">
    <img src="file/NLGraph_teaser.jpg" alt="NLGraph Teaser">
  </div>
  <div class="grid-item">
    <p>
      <b>Can Language Models Solve Graph Problems in Natural Language?</b>
    </p>
    <p>
        <a href="https://arthur-heng.github.io/">Heng Wang=</a>, <b>Shangbin Feng=</b>, <a href="https://people.csail.mit.edu/cloudygoose/">Tianxing He</a>, <a href="https://zhaoxuan.info/">Zhaoxuan Tan</a>, <a href="https://xhan77.github.io/">Xiaochuang Han</a>, <a href="https://homes.cs.washington.edu/~yuliats/">Yulia Tsvetkov</a>
    </p>
    <p>
      NeurIPS 2023, spotlight &nbsp
      <a href="https://arxiv.org/abs/2305.10037" class="button">paper</a> &nbsp
      <a href="https://github.com/Arthur-Heng/NLGraph" class="button">code</a> &nbsp
    </p>
    <p>
       Are language models graph reasoners? We propose the NLGraph benchmark, a test bed for graph-based reasoning designed for language models in natural language. We find that LLMs are preliminary graph thinkers while the most advanced graph reasoning tasks remain an open research question.
    </p>
  </div>
  <div class="grid-item"></div>
</div>
    
<div class="grid-container">
  <div class="grid-item"></div>
  <div class="grid-item">
    <img src="file/PoliLean_teaser.jpg" alt="PoliLean Teaser">
  </div>
  <div class="grid-item">
    <p>
      <b>From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models</b>
    </p>
    <p>
        <b>Shangbin Feng</b>, <a href="https://chan0park.github.io/">Chan Young Park</a>, <a href="https://lyh6560new.github.io/">Yuhan Liu</a>, <a href="https://homes.cs.washington.edu/~yuliats/">Yulia Tsvetkov</a> 
    </p>
    <p>
      ACL 2023 &nbsp üèÜ Best Paper Award &nbsp
      <a href="https://arxiv.org/abs/2305.08283" class="button">paper</a> &nbsp
      <a href="https://github.com/BunsenFeng/PoliLean" class="button">code</a> &nbsp
      <a href="https://www.washingtonpost.com/technology/2023/08/16/chatgpt-ai-political-bias-research/" class="button">Washington Post</a> &nbsp  
      <a href="https://www.technologyreview.com/2023/08/07/1077324/ai-language-models-are-rife-with-political-biases/" class="button">MIT Tech Review</a> &nbsp
      <a href="https://montrealethics.ai/from-pretraining-data-to-language-models-to-downstream-tasks-tracking-the-trails-of-political-biases-leading-to-unfair-nlp-models/" class="button">Montreal AI Ethics Institute</a> &nbsp
      <a href="https://www.betterconflictbulletin.org/p/do-the-bots-have-a-blue-bias-bcb" class="button">Better Conflict Bulletin</a> &nbsp
    </p>
    <p>
      We propose to study the political bias propagation pipeline from pretraining data to language models to downstream tasks. We find that language models do have political biases, such biases are in part picked up from pretraining corpora, and they could result in fairness issues in LM-based solutions to downstream tasks.
    </p>
  </div>
  <div class="grid-item"></div>
</div>

<hr style="width:80%">

<div class="grid-container">
  <div class="grid-item"></div>
  <div class="grid-item">
    <p style="text-align:left;font-size:150%;">Miscellaneous</p>
  </div>
  <div class="grid-item"></div>
  <div class="grid-item"></div>
</div>

<div class="grid-container">
  <div class="grid-item"></div>
  <div class="grid-item"></div>
  <div class="grid-item">
    <ul>
      <li>My Chinese name is ÂÜØÂ∞öÂΩ¨.</li>
      <li>If my name comes second/third in an equal contribution, it means that I mentored the first author on the project.</li>
      <li>If you plan to contact me about code or resources in my papers, it is best to open an issue in the correpsonding GitHub repository.</li>
      <li>I did my undergrad at Xi'an Jiaotong University. I founded the <a href="https://luoundergradxjtu.github.io/">LUD Lab</a> while I was there.</li>
    </ul>
  </div>
  <div class="grid-item"></div>
</div>

</body>
</html>
